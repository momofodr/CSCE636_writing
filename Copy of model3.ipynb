{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of model3.ipynb","provenance":[{"file_id":"1zaqTloGO8_P5Zt6sxZqIM_O6Y1ustxsB","timestamp":1587093950689}],"mount_file_id":"1sc7aV0gy1FNBsC8wREMY4Ig0W4GSmmOp","authorship_tag":"ABX9TyOlteo7C2dgkm+qxzZVHn9C"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"-1f-zJn8RoJl","colab_type":"code","outputId":"7463e179-e2b6-4e89-ebfa-8a1120216125","executionInfo":{"status":"ok","timestamp":1587094535504,"user_tz":300,"elapsed":5762,"user":{"displayName":"Wenjing Chen","photoUrl":"","userId":"00210133438249402524"}},"colab":{"base_uri":"https://localhost:8080/","height":574}},"source":["% cd /content/drive/My Drive/Colab Notebooks/csce636/course_project\n","!pip install jsonlines\n","% ls"],"execution_count":11,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/csce636/course_project\n","Collecting jsonlines\n","  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.12.0)\n","Installing collected packages: jsonlines\n","Successfully installed jsonlines-1.2.0\n"," ava_train_v2.2.csv       model1.4_02-0.62.hdf5   model3_30-0.44.hdf5\n"," ava_val_v2.2.csv         model1.4_07-0.61.hdf5   model3_43-0.44.hdf5\n","'Copy of model_4.ipynb'   model1.4_08-0.59.hdf5   model3_44-0.37.hdf5\n"," \u001b[0m\u001b[01;34mlog\u001b[0m/                     model1.4_11-0.57.hdf5   model_4.ipynb\n"," model_01-0.55.hdf5       model1.4_13-0.43.hdf5   model_final.ipynb\n"," model_01-0.63.hdf5       model1.4_18-0.33.hdf5   model_l_01-0.61.hdf5\n"," model_02-0.56.hdf5       model1.5_01-0.68.hdf5   model_l_04-0.34.hdf5\n"," model_03-0.46.hdf5       model1.5_03-0.62.hdf5   model_l1.2_01-0.72.hdf5\n"," model_05-0.43.hdf5       model1.5_09-0.54.hdf5   model_l1.2_04-0.51.hdf5\n"," model_05-0.49.hdf5       model1.5_10-0.46.hdf5   model_l1.2_07-0.48.hdf5\n"," model1.2_01-0.72.hdf5    model1.5_28-0.37.hdf5   model_l1.2_15-0.30.hdf5\n"," model1.2_03-0.68.hdf5    model_23-0.31.hdf5      model_l1.3_01-0.56.hdf5\n"," model1.2_05-0.65.hdf5    model3_01-1.42.hdf5     model_l1.3_01-0.78.hdf5\n"," model1.2_07-0.64.hdf5    model3_02-0.85.hdf5     model_l1.3_02-0.67.hdf5\n"," model1.2_09-0.62.hdf5    model3_05-0.80.hdf5     model_l1.3_11-0.36.hdf5\n"," model1.2_12-0.58.hdf5    model3_10-0.48.hdf5     model_l1.3_24-0.28.hdf5\n"," model1.2_15-0.57.hdf5    model3.1_01-1.51.hdf5   picture_extract.ipynb\n"," model1.2_18-0.54.hdf5    model3.1_03-1.45.hdf5   picture_extract-test.ipynb\n"," model1.3_01-0.77.hdf5    model3.1_27-1.33.hdf5   \u001b[01;34msample_frame1\u001b[0m/\n"," model1.3_02-0.61.hdf5    model3.1_28-1.11.hdf5   \u001b[01;34msample_frame2\u001b[0m/\n"," model1.3_08-0.57.hdf5    model3.1_42-1.03.hdf5   \u001b[01;34msample_frame3\u001b[0m/\n"," model1.3_09-0.46.hdf5    model3.1_44-0.51.hdf5   \u001b[01;34msample_frame4\u001b[0m/\n"," model1.3_21-0.44.hdf5    model3.2_01-2.01.hdf5   \u001b[01;34msample_frame5\u001b[0m/\n"," model1.3_26-0.42.hdf5    model3.2_02-1.79.hdf5   \u001b[01;34mtest\u001b[0m/\n"," model1.3_39-0.39.hdf5    model3.2_03-1.00.hdf5   \u001b[01;34mtrain\u001b[0m/\n"," model1.4_01-0.71.hdf5    model3.2_10-0.87.hdf5\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kXcAxQW7PndG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":87},"outputId":"6b29ae5d-63b5-4522-ee57-46f9be06e9be","executionInfo":{"status":"ok","timestamp":1587094569251,"user_tz":300,"elapsed":31637,"user":{"displayName":"Wenjing Chen","photoUrl":"","userId":"00210133438249402524"}}},"source":["from keras.applications.inception_v3 import InceptionV3\n","from keras.preprocessing import image\n","from keras.models import Model\n","from keras.layers import Dense, GlobalAveragePooling2D\n","from keras import backend as K\n","from keras import layers\n","from keras import optimizers\n","from keras import losses\n","from keras import metrics\n","from keras.optimizers import SGD\n","# create the base pre-trained model\n","base_model = InceptionV3(weights='imagenet', \n","                         include_top=False,\n","                         input_shape=(299,299,3),\n","                         pooling=None\n","                         )\n","\n","\n","\n","\n","\n","from keras.callbacks import ModelCheckpoint\n","from keras.layers import Dense, GlobalAveragePooling2D, Flatten\n","# add a global spatial average pooling layer\n","\n","\n","\n","x2 = base_model.output\n","x2 = GlobalAveragePooling2D()(x2)\n","predictions2 = Dense(1, activation='sigmoid')(x2)\n","\n","# this is the model we will train\n","model2 = Model(inputs=base_model.input, outputs=predictions2)\n","\n","# first: train only the top layers (which were randomly initialized)\n","# i.e. freeze all convolutional InceptionV3 layers\n","for layer in model2.layers[:249]:\n","   layer.trainable = False\n","for layer in model2.layers[249:]:\n","   layer.trainable = True\n","\n","# we need to recompile the model for these modifications to take effect\n","# we use SGD with a low learning rate\n","from keras.optimizers import SGD\n","model2.compile(optimizer=SGD(lr=0.001, momentum=0.9),\n","              loss='binary_crossentropy',\n","              metrics=['acc'])\n","#model.compile(loss=losses.binary_crossentropy,\n","            #optimizer=optimizers.RMSprop(lr=0.0001),\n","            #metrics=[metrics.binary_accuracy])\n","\n","model2.load_weights('model_l1.3_24-0.28.hdf5')#/content/drive/My Drive/Colab Notebooks/csce636/course_project/model_l1.3_24-0.28.hdf5"],"execution_count":12,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"stream","text":["Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n","87916544/87910968 [==============================] - 3s 0us/step\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7UNqhNWtTtdX","colab_type":"code","colab":{}},"source":["from __future__ import print_function\n","\n","import numpy as np\n","import cv2\n","import os\n","import time\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import jsonlines\n","\n","def prepare_frames_from_video(datadir, fps = 30.0):\n","    video_list = []\n","    times = []\n","    frames = []\n","    if os.path.isdir(datadir):\n","        for root, dirs, files in os.walk(datadir):\n","            for file in files:\n","                if '.mp4' in file:\n","                    video_list.append(os.path.join(root, file))\n","    elif os.path.isfile(datadir):\n","        video_list = [datadir]\n","    else:\n","        print('Dataset is empty.')\n","    \n","    frames_index = 0\n","    frame_time = 0\n","    for video in video_list:\n","        cap = cv2.VideoCapture(video)\n","        count_index = 0\n","        print(\"start loading \"+os.path.basename(video))\n","        t_start = time.time()\n","        while (True):\n","            success, frame = cap.read()\n","            if not success:\n","                break\n","            count_index += 1\n","            frame_time += 1\n","            if count_index == 10:\n","                frames.append(cv2.resize(frame,(299, 299))/255.)\n","                times.append(frame_time/float(fps))\n","                count_index = 0\n","                frames_index+=1\n","        print('loading data finished')\n","        t_end = time.time()\n","        print('time cost',t_end-t_start,'s')\n","        cap.release()\n","        cv2.destroyAllWindows()\n","\n","    return frames, os.path.basename(video), times\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xbbF1QtdRKlo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"outputId":"45616b33-04f1-463e-eeef-9935b2225143","executionInfo":{"status":"ok","timestamp":1587098061417,"user_tz":300,"elapsed":88772,"user":{"displayName":"Wenjing Chen","photoUrl":"","userId":"00210133438249402524"}}},"source":["frames, video, times = prepare_frames_from_video('/content/drive/My Drive/test/test5.mp4')\n","prob = model2.predict([frames])\n","pred = [int(p>0.5) for p in prob]\n","js = \"\"\n","for i, p in enumerate(prob):\n","    js += \"({},{}) \".format(times[i], p)\n","with jsonlines.open(\"/content/drive/My Drive/test/\"+video.split('.')[0]+\".jsonl\",mode='w') as writer:\n","    writer.write(js)\n","plt.plot(times, pred)\n","plt.xlabel('time (s)')\n","plt.ylabel('prediction')\n","plt.savefig(\"/content/drive/My Drive/test/\"+video.split('.')[0]+\".jpg\")\n","plt.clf()"],"execution_count":60,"outputs":[{"output_type":"stream","text":["start loading test5.mp4\n","loading data finished\n","time cost 20.542635679244995 s\n"],"name":"stdout"},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 0 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"QuyyQaZFV5PN","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}